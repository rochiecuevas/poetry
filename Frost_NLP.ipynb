{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robert Frost, meet Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies to read the SQLite database\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the poetry database\n",
    "conn = sqlite3.connect(\"Poetry.db\")\n",
    "\n",
    "# Load the data into a dataframe\n",
    "df = pd.read_sql_query(\"select * from Frost;\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Print the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"title\", \"lines\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenise, Remove Stop Words, Lemmatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from the list\n",
    "stops = stopwords.words(\"english\")\n",
    "punctuations = [\",\", \".\", \"/\", \"?\", \"!\", \";\", \":\", \"-\", \"’\", \"‘\",\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of words per poem and add that to an empty array\n",
    "words_list = []\n",
    "for poem in df[\"lines\"]:\n",
    "    words = word_tokenize(poem.lower())\n",
    "    words2 = [word for word in words if word not in stops and word not in punctuations]\n",
    "    words_list.append(words2)\n",
    "\n",
    "df[\"tokens\"] = words_list    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatise the words in each list to retain their roots\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "lemmatised = []\n",
    "for word in df[\"tokens\"][0]:\n",
    "    lemma = lemmatiser.lemmatize(word, pos = \"v\")\n",
    "    lemmatised.append(lemma)\n",
    "    \n",
    "lemmatised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that counts the number of words in each poem\n",
    "def word_count(word_list):\n",
    "    return len(word_list)\n",
    "\n",
    "# Define the function as a user-defined function (UDF)\n",
    "countWords = udf(word_count, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that calculates the difference between two columns, for each row\n",
    "def difference(a,b):\n",
    "    return a - b\n",
    "\n",
    "# State that this function is UDF\n",
    "diffLength = udf(difference, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tokeniser to split the string of words into a list of words\n",
    "spark_df2 = tokeniser.transform(spark_df)\n",
    "\n",
    "# Remove stop words from the wordList\n",
    "spark_df3 = remover.transform(spark_df2)\\\n",
    "                   .select(\"title\",\"wordList\", \"filteredList\")\n",
    "\n",
    "# Stem the words\n",
    "spark_df4 = spark_df3.withColumn(\"stemmed\", stemmer_udf(col(\"filteredList\")))\n",
    "spark_df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe that has the word count per poem\n",
    "spark_df5 = spark_df4.withColumn(\"wordCount\", countWords(col(\"wordList\")))\n",
    "spark_df5 = spark_df5.withColumn(\"filteredCount\", countWords(col(\"filteredList\")))\n",
    "spark_df5 = spark_df5.withColumn(\"stopWordsCount\", diffLength(\"wordCount\", \"filteredCount\"))\n",
    "spark_df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "spark_df5.select(\"wordCount\", \"filteredCount\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The longest poem by Robert Frost\n",
    "print(f\"--Longest Poem-- \\\n",
    "      \\nTitle: '{spark_df5.rdd.max(key = lambda x: x['wordCount'])[0]}', \\\n",
    "      \\nNumber of words: {spark_df5.rdd.max(key = lambda x: x['wordCount'])[4]}\")\n",
    "\n",
    "# Shortest poem by Robert Frost\n",
    "print(f\"\\n--Shortest Poem-- \\\n",
    "      \\nTitle: '{spark_df5.rdd.min(key = lambda x: x['wordCount'])[0]}', \\\n",
    "      \\nNumber of words: {spark_df5.rdd.min(key = lambda x: x['wordCount'])[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = spark_df5.select(\"stemmed\").show()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
