{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poets, meet Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies to read the SQLite database\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(poet):\n",
    "    \"\"\" Load the data from database into a dataframe \"\"\"\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {poet};\", conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the poetry database\n",
    "conn = sqlite3.connect(\"db/Poetry.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of unique poets\n",
    "poet_list = [\"Frost\", \"Yeats\", \"Kipling\"]\n",
    "\n",
    "# Iterate through the list to create a list of dataframes\n",
    "poems_df = [create_dataframe(poet) for poet in poet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>lines</th>\n",
       "      <th>poet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Ben Bulben</td>\n",
       "      <td>https://www.poetryfoundation.org/poems/43298/u...</td>\n",
       "      <td>I\\n Swear by what the Sages spoke,\\n Round the...</td>\n",
       "      <td>William Butler Yeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A Coat</td>\n",
       "      <td>https://www.poetryfoundation.org/poetrymagazin...</td>\n",
       "      <td>I made my song a coat,Covered with embroiderie...</td>\n",
       "      <td>William Butler Yeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A Dialogue of Self and Soul</td>\n",
       "      <td>https://www.poetryfoundation.org/poems/43294/a...</td>\n",
       "      <td>IMy Soul. I summon to the winding ancient stai...</td>\n",
       "      <td>William Butler Yeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A Drinking Song</td>\n",
       "      <td>https://www.poetryfoundation.org/poems/50337/a...</td>\n",
       "      <td>Wine comes in at the mouth,\\n And love comes i...</td>\n",
       "      <td>William Butler Yeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A Meditation in Time of War</td>\n",
       "      <td>https://www.poetryfoundation.org/poems/57318/a...</td>\n",
       "      <td>For one throb of the artery, ,While on that ol...</td>\n",
       "      <td>William Butler Yeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        title  \\\n",
       "0      0             Under Ben Bulben   \n",
       "1      1                       A Coat   \n",
       "2      2  A Dialogue of Self and Soul   \n",
       "3      3              A Drinking Song   \n",
       "4      4  A Meditation in Time of War   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.poetryfoundation.org/poems/43298/u...   \n",
       "1  https://www.poetryfoundation.org/poetrymagazin...   \n",
       "2  https://www.poetryfoundation.org/poems/43294/a...   \n",
       "3  https://www.poetryfoundation.org/poems/50337/a...   \n",
       "4  https://www.poetryfoundation.org/poems/57318/a...   \n",
       "\n",
       "                                               lines                  poet  \n",
       "0  I\\n Swear by what the Sages spoke,\\n Round the...  William Butler Yeats  \n",
       "1  I made my song a coat,Covered with embroiderie...  William Butler Yeats  \n",
       "2  IMy Soul. I summon to the winding ancient stai...  William Butler Yeats  \n",
       "3  Wine comes in at the mouth,\\n And love comes i...  William Butler Yeats  \n",
       "4  For one throb of the artery, ,While on that ol...  William Butler Yeats  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the dataframes\n",
    "poems_df[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect from the poetry database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that selects the relevant columns\n",
    "def BuildDataframe(df):\n",
    "    \"\"\" Create a new dataframe containing metadata \"\"\"\n",
    "    \n",
    "    df1 = df[[\"title\", \"poet\"]] # Select the relevant columns from the dataframe\n",
    "    \n",
    "    lines = df[\"lines\"].values.tolist() # Convert the lines column into a list of strings\n",
    "    df1[\"lines\"] = [x.replace(\"\\n\", \" \") for x in lines] # Remove special characters and white spaces \n",
    "    df1[\"lines\"] = df1[\"lines\"].str.lower() # Put all letters in lower case\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# For each dataframe, choose the relevant columns\n",
    "poems_df1 = [BuildDataframe(df) for df in poems_df] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>poet</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prelude</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>(to departmental ditties)i have eaten your bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A General Summary</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>we are very slightly changed from the semi-ape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Army Headquarters</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>old is the song that i sing old as my unpaid b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Study of an Elevation, in Indian Ink</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>this ditty is a string of lies. buthow the deu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delilah</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>we have another viceroy now, those days are de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title             poet  \\\n",
       "0                               Prelude  Rudyard Kipling   \n",
       "1                     A General Summary  Rudyard Kipling   \n",
       "2                     Army Headquarters  Rudyard Kipling   \n",
       "3  Study of an Elevation, in Indian Ink  Rudyard Kipling   \n",
       "4                               Delilah  Rudyard Kipling   \n",
       "\n",
       "                                               lines  \n",
       "0  (to departmental ditties)i have eaten your bre...  \n",
       "1  we are very slightly changed from the semi-ape...  \n",
       "2  old is the song that i sing old as my unpaid b...  \n",
       "3  this ditty is a string of lies. buthow the deu...  \n",
       "4  we have another viceroy now, those days are de...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview each dataframe\n",
    "# [0] = Frost, [1] = Yeats, [2] = Kipling\n",
    "poems_df1[2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting metadata about the poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about publication year (various sources)\n",
    "pubyear_Frost = [1913, 1916, 1928, 1914, 1916, 1916, 1923, 1923, 1928, 1923,\n",
    "           1923, 1923, 1920, 1914, 1923, 1913, 1914, 1913, 1917, 1923,\n",
    "           1916, 1913, 1923, 1923, 1923, 1914, 1942, 1923, 1916, 1914,\n",
    "           1916, 1918, 1916, 1923, 1913, 1914, 1920]\n",
    "\n",
    "pubyear_Yeats = [1938, 1914, 1933, 1916, 1921, 1919, 1904, 1913, 1919, 1933,\n",
    "                 1932, 1889, 1916, 1898, 1927, 1938, 1904, 1916, 1921, 1915,\n",
    "                 1938, 1909, 1928, 1916, 1916, 1899, 1939, 1916, 1899, 1916,\n",
    "                 1899, 1917, 1892, 1914, 1917, 1889, 1921, 1889, 1899, 1892,\n",
    "                 1928, 1917, 1914, 1889, 1892, 1892, 1892, 1933, 1914, 1933,\n",
    "                 1917, 1914, 1933, 1912, 1919, 1935, 1917, 1914, 1934, 1934,\n",
    "                 1934, 1916, 1916, 1935, 1916, 1919, 1912, 1919, 1914, 1916,\n",
    "                 1916, 1912, 1919, 1916, 1916, 1914, 1912, 1934, 1914, 1912,\n",
    "                 1914, 1916]\n",
    "\n",
    "pubyear_Kipling = [1922] * 416 + [1919, 1922, 1920, 1902, 1904, 1895, 1904, 1917, 1895, 1916, \n",
    "                                  1920, 1919, 1922, 1921, 1922, 1919, 1902, 1922, 1904, 1895,\n",
    "                                  1917, 1920, 1895, 1922, 1896, 1895, 1922, 1895, 1917, 1917,\n",
    "                                  1920, 1915, 1922, 1922]\n",
    "\n",
    "pubyears_list = [pubyear_Frost, pubyear_Yeats, pubyear_Kipling] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of titles, lines, and poets for each dataframe\n",
    "titles_list = []\n",
    "lines_list = []\n",
    "poets_list = []\n",
    "\n",
    "for df in poems_df1:\n",
    "    titles = df[\"title\"].values.tolist()\n",
    "    lines = df[\"lines\"].values.tolist()\n",
    "    poets = df[\"poet\"].values.tolist()\n",
    "    \n",
    "    titles_list.append(titles)\n",
    "    lines_list.append(lines)\n",
    "    poets_list.append(poets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get length of the entire poem for each poem in each dataframe\n",
    "lengths_list = []\n",
    "for lines in lines_list:\n",
    "    poem_length = [len(line.split()) for line in lines]\n",
    "    lengths_list.append(poem_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique words; how many unique words per poem?\n",
    "unique_words = [[list(set(line.split())) for line in lines_list[x]] for x in range(0, len(lines_list))]\n",
    "uniqueLength_list = [[len(y) for y in unique_words[x]] for x in range(0, len(unique_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical diversity: proportion of unique words among all the words in the poem\n",
    "# NB: No filtering has been done to remove stop words, punctuations, etc.\n",
    "lexical_diversity_list = []\n",
    "for x in range(0, len(lengths_list)):\n",
    "    lex_divs = []\n",
    "    for i in range(0, len(lengths_list[x])):\n",
    "        lex_div = round(uniqueLength_list[x][i]/lengths_list[x][i], 4)\n",
    "        lex_divs.append(lex_div)\n",
    "    lexical_diversity_list.append(lex_divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import re, string\n",
    "\n",
    "import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenise, Remove Stop Words, Lemmatise\n",
    "Reference for lemmatisation: https://marcobonzanini.com/2015/01/26/stemming-lemmatisation-and-pos-tagging-with-python-and-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from the list\n",
    "stops = stopwords.words(\"english\")\n",
    "exclude = list(set(string.punctuation)) + [\"’\", \"—\", \"‘\"]\n",
    "\n",
    "# Lemmatise the words in each list to retain their roots\n",
    "lemmatiser = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniser(poem):\n",
    "    \"\"\" Processes the poem into tokens and removes stop words, numbers, and punctuations \"\"\"\n",
    "    words_list = []\n",
    "    preprocessed_text = []\n",
    "    \n",
    "    words = word_tokenize(poem) # Create a list of words\n",
    "    words2 = [word for word in words if word not in stops] # Filter the keywords\n",
    "    words2 = [word for word in words2 if word not in exclude] # Filter out punctuations\n",
    "    words3 = [lemmatiser.lemmatize(word, pos = \"v\") for word in words2] # Lemmatise each word\n",
    "    words_list.append(words3) # Add the filtered list of words (representing each poem)\n",
    "    words4 = \" \".join(words3) # Convert the list of strings back to one string\n",
    "    preprocessed_text.append(words4) # Add the string (representing each poem) to the list\n",
    "    \n",
    "    return words_list, preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise each poem in each dataframe\n",
    "tokenised_poems = [[tokeniser(poem) for poem in lines] for lines in lines_list]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens = []\n",
    "df_filtered = []\n",
    "for x in range(len(tokenised_poems)):\n",
    "    token_lists = []\n",
    "    filtered_lists = []\n",
    "    \n",
    "    for y in range (len(tokenised_poems[x])):\n",
    "        token_list = tokenised_poems[x][y][0][0]\n",
    "        token_lists.append(token_list)\n",
    "        \n",
    "        filtered_list = tokenised_poems[x][y][1][0]\n",
    "        filtered_lists.append(filtered_list)\n",
    "        \n",
    "    df_tokens.append(token_lists)    \n",
    "    df_filtered.append(filtered_lists) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hush october morning mild thy leave ripen fall tomorrow wind wild waste crow forest call tomorrow may form go hush october morning mild begin hours day slow make day seem us less brief hearts averse beguile beguile us way know release one leaf break day noon release another leaf one tree one far away retard sun gentle mist enchant land amethyst slow slow grapes sake whose leave already burn frost whose cluster fruit must else lost— grapes sake along wall',\n",
       " 'buzz saw snarl rattle yard make dust drop stove-length stick wood sweet-scented stuff breeze draw across lift eye could count five mountain range one behind sunset far vermont saw snarl rattle snarl rattle run light bear load nothing happen day do call day wish might say please boy give half hour boy count much save work sister stand beside apron tell supper. word saw prove saw know supper mean leap boy hand seem leap— must give hand however neither refuse meet hand boy first outcry rueful laugh swing toward hold hand half appeal half keep life spill boy saw all— since old enough know big boy man work though child heart— saw spoil let cut hand off— doctor come let sister hand go already doctor put dark ether lay puff lips breath then—the watcher pulse take fright one believe listen heart little—less—nothing —and end build since one dead turn affairs',\n",
       " 'one acquaint night walk rain—and back rain outwalked furthest city light look saddest city lane pass watchman beat drop eye unwilling explain stand still stop sound feet far away interrupt cry come house another street call back say good-bye still unearthly height one luminary clock sky proclaim time neither wrong right one acquaint night',\n",
       " \"long two-pointed ladder 's stick tree toward heaven still 's barrel n't fill beside may two three apples n't pick upon bough do apple-picking essence winter sleep night scent apples drowse rub strangeness sight get look pane glass skim morning drink trough hold world hoary grass melt let fall break well upon way sleep fell could tell form dream take magnify apples appear disappear stem end blossom end every fleck russet show clear instep arch keep ache keep pressure ladder-round feel ladder sway boughs bend keep hear cellar bin rumble sound load load apples come much apple-picking overtire great harvest desire ten thousand thousand fruit touch cherish hand lift let fall strike earth matter bruise spike stubble go surely cider-apple heap worth one see trouble sleep mine whatever sleep go woodchuck could say whether 's like long sleep describe come human sleep\",\n",
       " \"see birch bend leave right across line straighter darker tree like think boy 's swing swing n't bend stay ice-storms often must see load ice sunny winter morning rain click upon breeze rise turn many-colored stir crack craze enamel soon sun 's warmth make shed crystal shell shatter avalanche snow-crust— heap break glass sweep away 'd think inner dome heaven fall drag wither bracken load seem break though bow low long never right may see trunks arch woods years afterwards trail leave grind like girls hand knees throw hair head dry sun go say truth break matter-of-fact ice-storm prefer boy bend go fetch cows— boy far town learn baseball whose play find summer winter could play alone one one subdue father 's tree rid take stiffness one hang limp one leave conquer learn learn launch soon carry tree away clear grind always keep poise top branch climb carefully pain use fill cup brim even brim fling outward feet first swish kick way air grind swinger birch dream go back 's 'm weary considerations life much like pathless wood face burn tickle cobwebs break across one eye weep twig 's lash across open 'd like get away earth awhile come back begin may fate willfully misunderstand half grant wish snatch away return earth 's right place love n't know 's likely go better 'd like go climb birch tree climb black branch snow-white trunk toward heaven till tree could bear dip top set would good go come back one could worse swinger birch\",\n",
       " 'city withdraw leave last country country whirl snow come lie whirl foliage yet lay drive stranger yard look city yet country fashion sit wait till draw us a-buttoning coat ask prove city come look something leave behind could without keep christmas ask would sell christmas tree woods—the young fir balsams like place house church spires think christmas tree doubt tempt moment sell feet go cars leave slope behind house bare sun shin warmer moon hate know yet hate hold tree except others hold refuse beyond time profitable growth trial market everything must come dally much think sell whether mistake courtesy fear seem short speech whether hope hear good mine say “ enough worth while. ” “ could soon tell many would cut let look over. ” “ could look expect go let them. ” pasture spring clump close lop boughs quite solitary equal boughs round round latter nod “ yes ” pause say beneath lovelier one buyer moderation “ would do. ” think say climb pasture south cross come north say “ thousand. ” “ thousand christmas tree —at apiece ” felt need soften “ thousand tree would come thirty dollars. ” certain never mean let never show surprise thirty dollars seem small beside extent pasture strip three cents figure apiece three cents small beside dollar friends write within hour would pay cities good tree like regular vestry-trees whole sunday school could hang enough pick enough thousand christmas tree know worth three cents give away sell may show simple calculation bad lay one letter help wish could send one',\n",
       " 'way crow shake dust snow hemlock tree give heart change mood save part day rue',\n",
       " 'say world end fire say ice taste desire hold favor fire perish twice think know enough hate say destruction ice also great would suffice',\n",
       " \"come real star fill upper sky earth come emulate fly though never equal star size never really star heart achieve time star-like start course ca n't sustain part\",\n",
       " 'others taunt kneel well-curbs always wrong light never see deeper well water give back shin surface picture summer heaven godlike look wreath fern cloud puff try chin well-curb discern think beyond picture picture something white uncertain something depths—and lose water come rebuke clear water one drop fell fern lo ripple shake whatever lay bottom blur blot whiten truth pebble quartz something',\n",
       " 'make much fragmentary blue bird butterfly flower wearing-stone open eye heaven present sheet solid hue since earth earth perhaps heaven yet though savants make earth include sky blue far us come high give wish blue whet',\n",
       " 'spade take leave better spoon bag full leave light balloon make great noise rustle day like rabbit deer run away mountains raise elude embrace flow arm face may load unload till fill whole shed next nothing weight since grow duller contact earth next nothing color next nothing use crop crop say harvest shall stop',\n",
       " \"say good-by edge dark cold orchard young bark remind happen harm orchard away end farm winter cut hill house n't want girdle rabbit mouse n't want dreamily nibble browse deer n't want bud grouse certain would n't idle call 'd summon grouse rabbit deer wall warn away stick gun n't want stir heat sun make secure hope set northerly slope orchard 's worse wintriest storm one thing must n't get warm `` often already 've tell keep cold young orchard good-by keep cold dread fifty fifty '' go season business awhile different tree less carefully nourish less fruitful do wood ax— maples birch tamaracks wish could promise lie night think orchard 's arboreal plight slowly nobody come light heart sink lower sod something leave god\",\n",
       " \"saw bottom stairs saw start look back shoulder fear take doubtful step undo raise look speak advance toward see always—for want know. turn sink upon skirt face change terrify dull say gain time see mount cower find now—you must tell dear. place refuse help least stiffen neck silence let look sure see blind creature awhile see last murmur oh oh. it—what say see. challenge tell is. wonder see never notice must wonted it—that reason little graveyard people small window frame whole much larger bedroom three stone slate one marble broad-shouldered little slabs sunlight sidehill mind understand stone child mound— cry withdraw shrink beneath arm rest banister slide downstairs turn daunt look say twice know man speak child lose oh hat oh need must get must get air know rightly whether man can. amy go someone else time listen come stairs. sit fix chin fists something like ask dear. know ask it. help then. finger move latch reply word nearly always offense know speak anything please might teach suppose say see man must partly give man women-folk could arrangement bind keep hand anything special a-mind name though like things twixt love two love live together without two live together them. move latch little t—don go carry someone else time tell something human let grief much unlike folks stand apart would make give chance think though overdo little bring think thing take mother-loss first child inconsolably—in face love think memory might satisfied— go sneer make angry come god woman come man speak child dead. n't know speak feel dig hand—how could —his little grave saw window make gravel leap leap air leap like like land lightly roll back mound beside hole think man know creep stairs stairs look still spade keep lift come hear rumble voice kitchen know go near see eye could sit stain shoe fresh earth baby grave talk everyday concern stand spade wall outside entry saw it. shall laugh worst laugh ever laugh curse god believe cursed. repeat word say “ three foggy mornings one rainy day rot best birch fence man build. ” think talk like time long take birch rot darken parlor care nearest friends go anyone death come far short might well try go time one sick death one alone die alone friends make pretense follow grave one mind turn make best way back life live people things understand world evil grief change oh say feel better go cry close door heart go keep amy someone come road you—oh think talk must go— somewhere house make you— if—you—do open door wider mean go first tell follow bring back force\",\n",
       " 'live come grassy tread read gravestones hill graveyard draw live still never dead verse say say ones live come today read stone go away tomorrow dead come stay. sure death marble rhyme yet help mark time one dead seem come men shrink would easy clever tell stone men hate die stop die forever think would believe lie',\n",
       " 'stranger come door eve speak bridegroom fair bore green-white stick hand burden care ask eye lips shelter night turn look road afar without window light bridegroom come forth porch let us look sky question night stranger i. woodbine leave litter yard woodbine berry blue autumn yes winter wind stranger wish knew. within bride dusk alone bend open fire face rose-red glow coal think heart desire bridegroom look weary road yet saw within wish heart case gold pin silver pin bridegroom think little give dole bread purse heartfelt prayer poor god rich curse whether man ask mar love two harbor woe bridal house bridegroom wish know',\n",
       " \"something n't love wall send frozen-ground-swell spill upper boulders sun make gap even two pass abreast work hunters another thing come make repair leave one stone stone would rabbit hide please yelp dog gap mean one see make hear make spring mending-time find let neighbour know beyond hill day meet walk line set wall us keep wall us go boulders fall loaves nearly ball use spell make balance `` stay back turn '' wear finger rough handle oh another kind out-door game one side come little need wall pine apple orchard apple tree never get across eat con pin tell say `` good fence make good neighbour '' spring mischief wonder could put notion head `` make good neighbour n't cow cow build wall 'd ask know wall wall like give offence something n't love wall want '' could say `` elves '' 's elves exactly 'd rather say see bring stone grasp firmly top hand like old-stone savage arm move darkness seem woods shade tree go behind father 's say like think well say `` good fence make good neighbour ''\",\n",
       " 'never sound beside wood one long scythe whisper grind whisper know well perhaps something heat sun something perhaps lack sound— whisper speak dream gift idle hours easy gold hand fay elf anything truth would seem weak earnest love lay swale row without feeble-pointed spike flower pale orchises scar bright green snake fact sweetest dream labor know long scythe whisper leave hay make',\n",
       " 'send back letter come say could could sure hide ill formal write live give back alive— else know send dead— disfigure visibly face hand look ask dear give still all—they had—they lucky glad everything seem rest permissible ease ask dear enough yet enough bullet high breast nothing good care medicine rest week cure go again. grim give dare ask eye second trial eye ask ask give back keep',\n",
       " 'nature first green gold hardest hue hold early leaf flower hour leaf subside leaf eden sink grief dawn go day nothing gold stay',\n",
       " \"battle rent cobweb diamond-strung cut flower beside grind bird 's nest stain single human breast stricken flower bend double hang still bird revisit young butterfly fall dispossess moment seek air flower rest lightly stoop flutter cling bare upland pasture spread o'ernight 'twixt mullein stalk wheel thread strain cable wet silver dew sudden pass bullet shake dry indwell spider run greet fly find nothing sullenly withdraw\",\n",
       " 'field woods wall wend climb hill view look world descend come highway home lo end leave dead grind save oak keep ravel one one let go scrap creep crust snow others sleep dead leave lie huddle still longer blow hither thither last lone aster go flower witch hazel wither heart still ache seek feet question whither ah heart man ever less treason go drift things yield grace reason bow accept end love season',\n",
       " 'whose woods think know house village though see stop watch woods fill snow little horse must think queer stop without farmhouse near woods freeze lake darkest even year give harness bell shake ask mistake sound sweep easy wind downy flake woods lovely dark deep promise keep miles go sleep miles go sleep',\n",
       " 'man come blow right wind blow unteach loudest day night rough place catch man come tell wrong find place blow blow hard—the aim song listen—how ought go take little mouth hold long enough north convert south measure blow forth measure word note wind wind mean be— little lips throat aim song—the wind could see',\n",
       " 'come errand one cloud-blowing even slab-built black-paper-covered house one room one window one door dwell waste cut hundred square miles round mountains dwell men women never dwell though women make sorrow come census-taker waste count people find none none hundred miles none house come last hope much hours overlook cliffs emptiness flay stone find people dare show none hide outward eye time autumn anyone could tell time year every tree could drop leaf nothing stump leave bring ring sugar pitch every tree stand rot trunk without single leaf spend autumn branch whistle spend perhaps wind without help breathe tree say something time year day way swing door forever latch rude men pass slam shut one behind next one open count nine right count dreamy unofficial count make tenth across threshold supper anyone lamp light nothing table stave cold—the stave chimney— one side lack leg people loudly pass door people ear eye table elbow sleep shelve bunk saw men bone men arm bone might pitch-blackened stub ax-handle pick straw-dust cover floor bone ill-fitted window rattle door still hold shut think could done— house—about people house one year fall decay fill less sorrow house fall ruin ten thousand years asia wedge africa europe nothing leave could see unless find one declare cliffs far echo “ place desert let whoso lurk silence aggrieve break silence forever silent let say declare so. ” melancholy count souls grow fewer fewer every year extreme shrink none must want life go live',\n",
       " \"mary sit muse lamp-flame table wait warren hear step run tip-toe darken passage meet doorway news put guard silas back. push outward door shut kind say take market things warren arm set porch draw sit beside wooden step ever anything kind fellow back say tell last hay leave say end good else harbor age little help depend go always need think ought earn little pay enough least buy tobacco beg behold “ right ” say “ afford pay fix wag though wish could. ” “ someone else can. ” “ someone else to. ” mind better certain begin like someone try coax pocket-money hay time help scarce winter come back us done. sh loud hear mary say want soon late. wear asleep beside stave come rowe find huddle barn-door fast asleep miserable sight frighten too— smile—i recognize him— look him—and change wait till see. say say drag house give tea try make smoke try make talk travel nothing would keep nod off. say say anything little. anything mary confess say come ditch meadow me. warren want know. course would say surely grudge poor old man humble way save self-respect add really care know mean clear upper pasture sound like something hear warren wish could hear way jumble everything stop look two three times—he make feel queer— see talk sleep run harold wilson—you remember— boy hay four years since finish school teach college silas declare get back say two make team work lay farm smooth way mix things think young wilson likely lad though daft education—you know fight july blaze sun silas cart build load harold along beside pitch on. yes take care keep well earshot. well days trouble silas like dream think would things linger harold young college boy assurance pique many years still keep find good arguments see might use sympathize know feel think right thing say late harold associate mind latin ask think harold say study latin like violin like it—that argument say make boy believe could find water hazel prong— show much good school ever do want go think could another chance teach build load hay— know silas one accomplishment bundle every forkful place tag number future reference find easily dislodge unload silas well take bunch like big bird nest never see stand hay try lift strain lift himself. think could teach good perhaps someone world hat see boy fool book poor silas concern folk nothing look backward pride nothing look forward hope never different. part moon fall west drag whole sky hill light pour softly lap saw spread apron put hand among harp-like morning-glory string taut dew garden bed eaves play unheard tenderness work beside night warren say come home die afraid leave time. home mock gently yes else home depend mean home course nothing us hound come stranger us woods wear upon trail. home place go take in. call something somehow deserve. warren lean take step two pick little stick bring back break hand toss silas better claim us think brother thirteen little miles road wind would bring door silas walk far doubt today go brother rich somebody—director bank. never tell us that. know though. think brother ought help course see need ought right take might will to— may better appearances pity silas think pride claim kin anything look brother keep still time wonder them. tell silas is—we mind him— kind kinsfolk abide never thing bad know quite good anyone worthless though make ashamed please brother. think si ever hurt anyone. hurt heart way lay roll old head sharp-edged chair-back let put lounge must go see make bed tonight surprise him—how much break work days do 'm sure it. hurry say that. go look see warren please remember come help ditch meadow plan laugh may speak may sit see small sail cloud hit miss moon. hit moon three make dim row moon little silver cloud warren returned—too soon seem slip side catch hand wait warren question dead answer\",\n",
       " 'land land land hundred years people massachusetts virginia england still colonials possess still unpossessed possess possess something withhold make us weak find withhold land live forthwith find salvation surrender give outright deed gift many deeds war land vaguely realize westward still unstoried artless unenhanced would become',\n",
       " 'house go bring midnight sky sunset glow chimney house stand like pistil petals go barn oppose across way would join house flame wind leave bear forsake place name open one end team come stony road drum floor scurry hoof brush mow summer load bird come air break windows fly murmur like sigh sigh much dwell yet lilac renew leaf age elm though touch fire dry pump fling awkward arm fence post carry strand wire really nothing sad though rejoice nest keep one verse country things believe phoebes weep',\n",
       " 'singer everyone hear loud mid-summer mid-wood bird make solid tree trunks sound say leave old flower mid-summer spring one ten say early petal-fall past pear cherry bloom go shower sunny days moment overcast come fall name fall say highway dust bird would cease bird know sing sing question frame word make diminish thing',\n",
       " \"'m go clean pasture spring 'll stop rake leave away wait watch water clear may sha'n't go long.—you come 'm go fetch little calf 's stand mother 's young totter lick tongue sha'n't go long.—you come\",\n",
       " 'two roads diverge yellow wood sorry could travel one traveler long stand look one far could bend undergrowth take fair perhaps better claim grassy want wear though pass wear really morning equally lay leave step tread black oh keep first another day yet know way lead way doubt ever come back shall tell sigh somewhere age age hence two roads diverge wood i— take one less travel make difference',\n",
       " \"snow year begin fall stop mountain pasture say whose colt little morgan one forefoot wall curl breast dip head snort us bolt hear miniature thunder flee saw think saw dim grey like shadow curtain fall flake think little fellow afraid snow winter-broken play little fellow run away doubt even mother could tell “ sakes weather. ” think know mother alone. come clatter stone mount wall white eye tail n't hair straight shudder coat throw fly whoever leave late creatures go stall bin ought tell come take\",\n",
       " 'wonder tree wish bear forever noise another noise close dwell place suffer day till lose measure pace fixity joy acquire listen air talk go never get away talk less know grow wiser older mean stay feet tug floor head sway shoulder sometimes watch tree sway window door shall set forth somewhere shall make reckless choice day voice toss scare white cloud shall less say shall go',\n",
       " \"`` know orion always come sideways throw leg fence mountains rise hand look busy outdoors lantern-light something do daylight indeed grind freeze do freeze gust fling handful waste leave smoky lantern chimney make fun way things else fun orion 's catch man like ask right force oblige pay respect '' brad mclaughlin mingle reckless talk heavenly star hugger-mugger farm till fail hugger-mugger farm burn house fire insurance spend proceed telescope satisfy lifelong curiosity place among infinities `` want one blame things '' ask well beforehand `` n't get one '' `` n't call blame n't anything blameless sense less weapon human fight '' say `` 'll one sell farm buy '' move rock plow grind plow rock could n't move farm change hand rather spend years try sell farm sell burn house fire insurance buy telescope come hear say several `` best thing 're put 's see strongest thing 's give us see 's telescope someone every town seem owe town keep one littleton may well '' loose talk surprise burn house mean laughter go town day let know n't least impose could wait—we 'd see tomorrow first thing next morning reflect one one count people least sin would n't take us long get one leave live social forgive thief one steal us n't cut come church suppers miss go ask promptly give back still uneaten unworn undisposed would n't hard brad telescope beyond age give one christmas gift take best way know find one well say take strange thing roguish sympathy waste house good old-timer date back along house n't sentient house n't feel anything regard sacrifice old-fashioned sacrifice fire instead new-fashioned one auction house farm one stroke match brad turn earn live concord railroad under-ticket-agent station job n't sell ticket set track plant farm planets even star vary hue red green get good glass six hundred dollars new job give leisure stargaze often bid come look brass barrel velvet black inside star quake end recollect night break cloud underfoot snow melt ice melt wind mud bradford telescope spread two legs spread three point thoughts way point stand leisure till day break say best things ever say telescope christen star-splitter n't thing split star two three way split globule quicksilver hand one stroke finger middle 's star-splitter ever one ought good split star 'sa thing compare split wood 've look look know better stand night tonight man smoky lantern chimney different way ever stand\",\n",
       " 'go turn grass one mow dew sun dew go make blade keen come view level scene look behind isle tree listen whetstone breeze go way grass mow must —alone must say within heart whether work together apart. say swift pass noiseless wing wildered butterfly seek memories grow dim er night rest flower yesterday delight mark flight go round round flower lay wither grind fly far eye could see tremulous wing come back think question reply would turn toss grass dry turn first lead eye look tall tuft flower beside brook leap tongue bloom scythe spar beside reedy brook scythe bar leave place know name find butterfly weed come mower dew love thus leave flourish us yet draw one think sheer morning gladness brim butterfly light upon nevertheless message dawn make hear waken bird around hear long scythe whisper grind feel spirit kindred henceforth work alone glad work aid weary seek noon shade dream hold brotherly speech one whose think hop reach men work together tell heart whether work together apart',\n",
       " \"walk freeze swamp one gray day pause say 'i turn back go farther—and shall see hard snow hold save one foot go view line straight tall slim tree much alike mark name place say certain somewhere else far home small bird fly careful put tree us light say word tell foolish think think think feather— white one tail like one take everything say personal one flight sideways would undeceive pile wood forget let little fear carry way might go without much wish good-night go behind make last stand cord maple cut split piled—and measure four four eight another like could see runner track year 's snow loop near older sure year 's cut even last year 's year 's wood gray bark warp pile somewhat sink clematis wind string round round like bundle hold though one side tree still grow one stake prop latter fall think someone live turn fresh task could forget handiwork spend labor ax leave far useful fireplace warm freeze swamp best could slow smokeless burn decay\",\n",
       " \"slumber poems breast spread open drop half-read like dive wing figure tomb see dream bring might chance miss life delay call face first soldier poet die soldier-poet race mean mean nothing remain unsay us brother remained— one thing say victory lose gain go meet shell 's embrace fire vimy ridge fell day war seem you—the way though even know foe thrust back unsafe beyond rhine speak see please word mine\"]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for x in range(len(poems_df1)):\n",
    "    poems_df1[x][\"tokens\"] = df_tokens[x]\n",
    "    poems_df1[x][\"filteredPoem\"] = df_filtered[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>poet</th>\n",
       "      <th>lines</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filteredPoem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prelude</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>(to departmental ditties)i have eaten your bre...</td>\n",
       "      <td>[departmental, ditties, eat, bread, salt, drin...</td>\n",
       "      <td>departmental ditties eat bread salt drink wate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A General Summary</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>we are very slightly changed from the semi-ape...</td>\n",
       "      <td>[slightly, change, semi-apes, range, indias, p...</td>\n",
       "      <td>slightly change semi-apes range indias prehist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Army Headquarters</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>old is the song that i sing old as my unpaid b...</td>\n",
       "      <td>[old, song, sing, old, unpaid, bill, old, chic...</td>\n",
       "      <td>old song sing old unpaid bill old chicken kitm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Study of an Elevation, in Indian Ink</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>this ditty is a string of lies. buthow the deu...</td>\n",
       "      <td>[ditty, string, lie, buthow, deuce, gubbins, r...</td>\n",
       "      <td>ditty string lie buthow deuce gubbins rise pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delilah</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>we have another viceroy now, those days are de...</td>\n",
       "      <td>[another, viceroy, days, dead, do, delilah, ab...</td>\n",
       "      <td>another viceroy days dead do delilah aberyswit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title             poet  \\\n",
       "0                               Prelude  Rudyard Kipling   \n",
       "1                     A General Summary  Rudyard Kipling   \n",
       "2                     Army Headquarters  Rudyard Kipling   \n",
       "3  Study of an Elevation, in Indian Ink  Rudyard Kipling   \n",
       "4                               Delilah  Rudyard Kipling   \n",
       "\n",
       "                                               lines  \\\n",
       "0  (to departmental ditties)i have eaten your bre...   \n",
       "1  we are very slightly changed from the semi-ape...   \n",
       "2  old is the song that i sing old as my unpaid b...   \n",
       "3  this ditty is a string of lies. buthow the deu...   \n",
       "4  we have another viceroy now, those days are de...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [departmental, ditties, eat, bread, salt, drin...   \n",
       "1  [slightly, change, semi-apes, range, indias, p...   \n",
       "2  [old, song, sing, old, unpaid, bill, old, chic...   \n",
       "3  [ditty, string, lie, buthow, deuce, gubbins, r...   \n",
       "4  [another, viceroy, days, dead, do, delilah, ab...   \n",
       "\n",
       "                                        filteredPoem  \n",
       "0  departmental ditties eat bread salt drink wate...  \n",
       "1  slightly change semi-apes range indias prehist...  \n",
       "2  old song sing old unpaid bill old chicken kitm...  \n",
       "3  ditty string lie buthow deuce gubbins rise pot...  \n",
       "4  another viceroy days dead do delilah aberyswit...  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_df1[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that counts the number of words in each poem\n",
    "def word_count(word_list):\n",
    "    return len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the length of each filtered poem\n",
    "lengths = []\n",
    "for poem in df1[\"tokens\"]:\n",
    "    length = word_count(poem)\n",
    "    lengths.append(length)\n",
    "\n",
    "# Add the filtered poem lengths in the df\n",
    "df1[\"poemLength\"] = lengths\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of poems\n",
    "print (f\"There are {df1.shape[0]} poems written by Robert Frost in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Longest and shortest poems\n",
    "longest_poem = df1[\"poemLength\"].max()\n",
    "shortest_poem = df1[\"poemLength\"].min()\n",
    "\n",
    "for i in range(0, len(df1[\"poemLength\"])):\n",
    "    if df1[\"poemLength\"][i] == longest_poem:\n",
    "        print(f'Longest poem: {df1[\"title\"][i]}; Filtered poem length: {df1[\"poemLength\"][i]} words')\n",
    "    if df1[\"poemLength\"][i] == shortest_poem:\n",
    "        print(f'Shortest poem: {df1[\"title\"][i]}; Filtered poem length: {df1[\"poemLength\"][i]} words')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word importance\n",
    "Source: https://stevenloria.com/tf-idf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import math\n",
    "from textblob import TextBlob as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that calculates term frequency\n",
    "def tf(word, poem):\n",
    "    return poem.words.count(word) / len(poem.words)\n",
    "\n",
    "# Create a function that determines the number of documents that contain a certain word\n",
    "def n_docs(word, poemlist):\n",
    "    return sum(1 for poem in poemlist if word in poem.words)\n",
    "\n",
    "# Create a function that determines the inverse document frequency (IDF)\n",
    "# IDF = how common a word is among all the documents in poemlist\n",
    "def idf(word, poemlist):\n",
    "    return math.log(len(poemlist) / (1 + n_docs(word, poemlist)))\n",
    "\n",
    "def tdidf(word, poem, poemlist):\n",
    "    return tf(word, poem) * idf(word, poemlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the poemlist from df[\"lines\"]\n",
    "poemlist = [tb(poem) for poem in df1[\"filteredPoem\"]]\n",
    "poemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to be filled with text blobs from cleaning poemlist\n",
    "poemlist2 = []\n",
    "\n",
    "# Loop through the poemlist\n",
    "for i in range(0, len(poemlist)):\n",
    "    \n",
    "    # Remove words that are shorter than 3 characters\n",
    "    new_string = ' '.join([w for w in str(poemlist[i]).split() if len(w) > 3])\n",
    "    \n",
    "    # Replace emm dash with space\n",
    "    new_string2 = new_string.replace(\"—\", \" \")\n",
    "    \n",
    "    # Convert string to text blob\n",
    "    new_string2 = tb(new_string2)\n",
    "    \n",
    "    # Append the text blob to the list of text blobs\n",
    "    poemlist2.append(new_string2)\n",
    "    \n",
    "poemlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the most important words\n",
    "impt_words = []\n",
    "for i, poem in enumerate(poemlist2):\n",
    "    scores = {word: tdidf(word, poem, poemlist2) for word in poem.words}\n",
    "    sorted_words = sorted(scores.items(), key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    for word, score in sorted_words[:5]:\n",
    "        impt_words.append((i, word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of important words per poem\n",
    "df2 = pd.DataFrame(impt_words, columns = [\"PoemNo\", \"Word\", \"TF-IDF\"])\n",
    "df2[\"Poet\"] = \"Robert Frost\"\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df2 as a sqlite database table (for Javascript use later)\n",
    "conn = sqlite3.connect(\"db/Poetry.db\")\n",
    "\n",
    "# Create a database table from the dataframe\n",
    "df2.to_sql(\"tfidf\", conn, if_exists = \"replace\", index = False)\n",
    "\n",
    "# Preview the database table\n",
    "pd.read_sql_query(\"select * from tfidf;\", conn).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add titles for each poem in df2\n",
    "titles = []\n",
    "for i in range(0, len(df)):\n",
    "    for p in df2.PoemNo:\n",
    "        if i == p:\n",
    "            title = df[\"title\"][i]\n",
    "            titles.append(title) \n",
    "\n",
    "df2[\"PoemTitle\"] = titles\n",
    "\n",
    "# Preview\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the important words by poem title\n",
    "df3 = pd.DataFrame(df2.groupby([\"PoemTitle\", \"Word\"])[\"TF-IDF\"].mean())\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\")\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import widgets, interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a widget containing poem titles (sorted alphabetically)\n",
    "titles = list(df.title)\n",
    "titles.sort()\n",
    "\n",
    "poem_title = widgets.Dropdown(options = [\"Choose a poem...\"] + titles, value = \"Choose a poem...\", \n",
    "                              description = \"Title:\", disabled = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter based on title\n",
    "def plot_it(poem_title):\n",
    "    if poem_title != \"Choose a poem...\":\n",
    "        df3 = df2[df2[\"PoemTitle\"] == poem_title]\n",
    "        \n",
    "        plt.figure(figsize = (10, 6))\n",
    "        sns.set(font_scale = 1.5)\n",
    "        graph = sns.barplot(y = \"Word\", x = \"TF-IDF\", data = df3, palette = \"Blues_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the data by poem title\n",
    "interactive(plot_it, poem_title = poem_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis - Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiments based on textblobs\n",
    "sentiment_polarity = [round(poem.sentiment.polarity, 3) \\\n",
    "                      for poem in poemlist2]\n",
    "sentiment_cat = [\"positive\" if sp > 0\n",
    "                 else \"negative\" if sp < 0\n",
    "                 else \"neutral\"\n",
    "                 for sp in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame({\"PoemNo\": index,\n",
    "                         \"Poet\": poets,\n",
    "                         \"Title\": poems,\n",
    "                         \"Content\": lines,\n",
    "                         \"Length\": poem_length,\n",
    "                         \"Sentiment\": sentiment_cat,\n",
    "                         \"Pubn_Year\": pubyear,\n",
    "                         \"Lexical_Diversity\": lex_div}, \n",
    "                        columns = [\"PoemNo\", \"Poet\", \"Title\", \"Length\", \n",
    "                                   \"Content\", \"Sentiment\", \"Pubn_Year\", \"Lexical_Diversity\"])\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df2 as a sqlite database table (for Javascript use later)\n",
    "conn = sqlite3.connect(\"db/Poetry.db\")\n",
    "\n",
    "# Create a database table from the dataframe\n",
    "metadata.to_sql(\"metadata\", conn, if_exists = \"replace\", index = False)\n",
    "\n",
    "# Preview the database table\n",
    "pd.read_sql_query(\"select * from metadata;\", conn).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling\n",
    "Sources: \n",
    "1. https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/\n",
    "2. https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim \n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df1[\"tokens\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and the trigram model\n",
    "bigram = gensim.models.Phrases(tokens, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[tokens], threshold=100) \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(texts, stop_words = stops, allowed_postags = [\"NOUN\", \"ADJ\", \"ADV\"]):\n",
    "    \"\"\" Remove stop words, create bigrams and trigrams, lemmatise \"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]    \n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    texts_out = []\n",
    "    \n",
    "    nlp = spacy.load(\"en\", disable = [\"parser\", \"ner\"])\n",
    "    \n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        \n",
    "        # remove stop words (again)         \n",
    "        texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] \\\n",
    "                     for doc in texts_out]\n",
    "        \n",
    "        # remove words shorter than three letters       \n",
    "        texts_out = [[word for word in lst if len(word) > 2] for lst in texts_out]\n",
    "\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_text = process_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "id2words = corpora.Dictionary(filtered_text)\n",
    "\n",
    "# Create corpus term frequency (convert dictionary to bag-of-words)\n",
    "corpus = [id2words.doc2bow(text) for text in filtered_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of number of topics\n",
    "num_topics = list(range(1, 21))\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that calculates the coherence score \n",
    "def coherence_score(num_topics):\n",
    "    \"\"\" Create a LDA model \"\"\"\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                            id2word = id2words,\n",
    "                                            num_topics = num_topics,\n",
    "                                            random_state = 100,\n",
    "                                            update_every = 1,\n",
    "                                            chunksize = 100,\n",
    "                                            passes = 20,\n",
    "                                            alpha = \"auto\",\n",
    "                                            per_word_topics = True)\n",
    "    \n",
    "    \"\"\" Calculate the coherence score \"\"\"\n",
    "    coherence_model_lda = CoherenceModel(model = lda_model, \n",
    "                                         texts = filtered_text, \n",
    "                                         dictionary = id2words,\n",
    "                                         coherence = 'c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    return coherence_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coherence score of each number of topics\n",
    "coh_score = [coherence_score(x) for x in num_topics]\n",
    "coh_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of topics vs coherence score\n",
    "# Find the highest coherence score before the trend flattens out\n",
    "plt.plot(num_topics, coh_score, \"bo-\")\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Coherence score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the LDA model using the chosen number of topics\n",
    "final_number = 6\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                            id2word = id2words,\n",
    "                                            num_topics = final_number,\n",
    "                                            random_state = 100,\n",
    "                                            update_every = 1,\n",
    "                                            chunksize = 100,\n",
    "                                            passes = 20,\n",
    "                                            alpha = \"auto\",\n",
    "                                            per_word_topics = True)\n",
    "\n",
    "# Compute Perplexity\n",
    "print(f\"Perplexity: {lda_model.log_perplexity(corpus)}\")\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model = lda_model, \n",
    "                                     texts = filtered_text, \n",
    "                                     dictionary = id2words, \n",
    "                                     coherence = 'c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Coherence Score: {coherence_lda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords for the top 10 topics\n",
    "doc_lda = lda_model[corpus]\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most important words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graphs of most important words per topic\n",
    "# Based on the LDA model\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.gensim.prepare(lda_model, corpus, id2words)\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph as a html page\n",
    "pyLDAvis.save_html(panel, \"lda.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dominant Topic in each poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_topics_sentences(doc_lda, ldamodel = lda_model, texts = tokens):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(doc_lda):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list \n",
    "        row = sorted(row, key = lambda x: (x[1]), reverse = True)\n",
    "        \n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), \\\n",
    "                                                                  topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(doc_lda, ldamodel = lda_model, texts = tokens)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of text per tokenised poem\n",
    "doc_lens = [len(d) for d in df_dominant_topic.Text]\n",
    "\n",
    "plt.figure(figsize = (10,3), dpi = 160)\n",
    "plt.hist(doc_lens, bins = 1000, color='navy')\n",
    "plt.text(200, 1.75, \"Mean   : \" + str(round(np.mean(doc_lens))))\n",
    "plt.text(200, 1.60, \"Median : \" + str(round(np.median(doc_lens))))\n",
    "plt.text(200, 1.45, \"Stdev   : \" + str(round(np.std(doc_lens))))\n",
    "plt.text(200, 1.30, \"1%ile    : \" + str(round(np.quantile(doc_lens, q = 0.01))))\n",
    "plt.text(200, 1.15, \"99%ile  : \" + str(round(np.quantile(doc_lens, q = 0.99))))\n",
    "\n",
    "plt.gca().set(xlim = (0, 300), ylabel = 'Number of Documents', xlabel = 'Document Word Count')\n",
    "plt.tick_params(size = 8)\n",
    "plt.xticks(np.linspace(0, 300, 9))\n",
    "plt.title('Distribution of Document Word Counts', fontdict = dict(size = 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "fig, axes = plt.subplots(3,2, figsize = (16,14), dpi = 160, sharex = True, sharey = True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):    \n",
    "    df_dominant_topic_sub = df_dominant_topic.loc[df_dominant_topic.Dominant_Topic == i, :]\n",
    "    doc_lens = [len(d) for d in df_dominant_topic_sub.Text]\n",
    "    ax.hist(doc_lens, bins = 1000, color = cols[i])\n",
    "    ax.tick_params(axis = 'y', labelcolor = cols[i], color = cols[i])\n",
    "    sns.kdeplot(doc_lens, color = \"black\", shade = False, ax = ax.twinx())\n",
    "    ax.set(xlim = (0, 300), xlabel = 'Document Word Count')\n",
    "    ax.set_ylabel('Number of Documents', color = cols[i])\n",
    "    ax.set_title('Topic: '+str(i), fontdict = dict(size = 8, color = cols[i]))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top = 0.90)\n",
    "plt.xticks(np.linspace(0, 300, 9))\n",
    "fig.suptitle('Distribution of Document Word Counts by Dominant Topic', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud of Top N words in each topic\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords = stops,\n",
    "                  background_color = 'white',\n",
    "                  width = 2500,\n",
    "                  height = 1800,\n",
    "                  max_words = 10,\n",
    "                  colormap = 'tab10',\n",
    "                  color_func = lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal = 1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize = (10,10), sharex = True, sharey = True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size = 300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size = 16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace = 0, hspace = 0)\n",
    "plt.axis('off')\n",
    "plt.margins(x = 0, y = 0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "topics = lda_model.show_topics(formatted = False)\n",
    "data_flat = [w for w_list in filtered_text for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(3, 2, figsize = (16,10), sharey = True, dpi = 160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x = 'word', \n",
    "           height = \"word_count\", \n",
    "           data = df.loc[df.topic_id == i, :], \n",
    "           color = cols[i], \n",
    "           width = 0.5, \n",
    "           alpha = 0.3, \n",
    "           label = 'Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x = 'word', \n",
    "                height = \"importance\", \n",
    "                data = df.loc[df.topic_id == i, :], \n",
    "                color = cols[i], width = 0.2,\n",
    "                label ='Weights')\n",
    "    ax.set_ylabel('Word Count', color = cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 50)\n",
    "    ax.set_title('Topic: ' + str(i), color = cols[i], fontsize = 16)\n",
    "    ax.tick_params(axis = 'y', left = False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id == i, 'word'], \n",
    "                       rotation = 30, \n",
    "                       horizontalalignment = 'right')\n",
    "    ax.legend(loc ='upper left')\n",
    "    ax_twin.legend(loc = 'upper right')\n",
    "\n",
    "fig.tight_layout(w_pad = 2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize = 14, y = 1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word colouring of N poems\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def sentences_chart(lda_model = lda_model, corpus = corpus, start = 0, end = 38):\n",
    "    corp = corpus[start:end]\n",
    "    mycolors = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "    fig, axes = plt.subplots(end-start, 1, figsize=(20, (end-start)*0.95), dpi=160)       \n",
    "    axes[0].axis('off')\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i > 0:\n",
    "            corp_cur = corp[i-1] \n",
    "            topic_percs, wordid_topics, wordid_phivalues = lda_model[corp_cur]\n",
    "            word_dominanttopic = [(lda_model.id2word[wd], topic[0]) for wd, topic in wordid_topics]    \n",
    "            ax.text(0.01, 0.5, \"Doc \" + str(i-1) + \": \", verticalalignment = 'center',\n",
    "                    fontsize = 16, color = 'black', transform = ax.transAxes, fontweight = 700)\n",
    "\n",
    "            # Draw Rectangle\n",
    "            topic_percs_sorted = sorted(topic_percs, key = lambda x: (x[1]), reverse = True)\n",
    "            ax.add_patch(Rectangle((0.0, 0.05), 0.99, 0.90, fill = None, alpha = 1, \n",
    "                                   color = mycolors[topic_percs_sorted[0][0]], linewidth = 2))\n",
    "\n",
    "            word_pos = 0.06\n",
    "            for j, (word, topics) in enumerate(word_dominanttopic):\n",
    "                if j < 14:\n",
    "                    ax.text(word_pos, 0.5, word,\n",
    "                            horizontalalignment = 'left',\n",
    "                            verticalalignment = 'center',\n",
    "                            fontsize = 16, \n",
    "                            color = mycolors[topics],\n",
    "                            transform = ax.transAxes, \n",
    "                            fontweight = 700)\n",
    "                    word_pos += .009 * len(word)  # to move the word for the next iter\n",
    "                    ax.axis('off')\n",
    "            ax.text(word_pos, 0.5, '. . .',\n",
    "                    horizontalalignment = 'left',\n",
    "                    verticalalignment = 'center',\n",
    "                    fontsize = 16, \n",
    "                    color = 'black',\n",
    "                    transform = ax.transAxes)       \n",
    "\n",
    "    plt.subplots_adjust(wspace = 0, hspace = 0)\n",
    "    plt.suptitle('Topic Coloring for Poems: ' + str(start) + ' to ' + str(end-2), \\\n",
    "                 fontsize = 14, y = 0.95, fontweight = 700)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "sentences_chart() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that identifies and quantifies the dominant topics\n",
    "def topics_per_document(model, corpus, start = 0, end = 1):\n",
    "    corpus_sel = corpus[start:end]\n",
    "    dominant_topics = []\n",
    "    topic_percentages = []\n",
    "    for i, corp in enumerate(corpus_sel):\n",
    "        topic_percs, wordid_topics, wordid_phivalues = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse = True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        topic_percentages.append(topic_percs)\n",
    "    \n",
    "    return(dominant_topics, topic_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_topics, topic_percentages = topics_per_document(model = lda_model, corpus = corpus, end = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Dominant Topics in Each Document\n",
    "df = pd.DataFrame(dominant_topics, columns = ['Document_Id', 'Dominant_Topic'])\n",
    "dominant_topic_in_each_doc = df.groupby('Dominant_Topic').size()\n",
    "df_dominant_topic_in_each_doc = dominant_topic_in_each_doc.to_frame(name = 'count').reset_index()\n",
    "\n",
    "# Total Topic Distribution by actual weight\n",
    "topic_weightage_by_doc = pd.DataFrame([dict(t) for t in topic_percentages])\n",
    "df_topic_weightage_by_doc = topic_weightage_by_doc.sum().to_frame(name = 'count').reset_index()\n",
    "\n",
    "# Top 3 Keywords for each Topic\n",
    "topic_top3words = [(i, topic) for i, topics in lda_model.show_topics(formatted = False) \n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "df_top3words_stacked = pd.DataFrame(topic_top3words, columns = ['topic_id', 'words'])\n",
    "df_top3words = df_top3words_stacked.groupby('topic_id').agg(', \\n'.join)\n",
    "df_top3words.reset_index(level =0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (10, 4), dpi = 120, sharex = True)\n",
    "\n",
    "# Topic Distribution by Dominant Topics\n",
    "ax1.bar(x = 'Dominant_Topic', \n",
    "        height = 'count', \n",
    "        data = df_dominant_topic_in_each_doc, \n",
    "        width = .5, color = 'firebrick')\n",
    "ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\\n' + \\\n",
    "                               df_top3words.loc[df_top3words.topic_id == x, 'words'].values[0])\n",
    "ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size = 10))\n",
    "ax1.set_ylabel('Number of Documents')\n",
    "ax1.set_ylim(0, 10)\n",
    "\n",
    "# Topic Distribution by Topic Weights\n",
    "ax2.bar(x = 'index', \n",
    "        height = 'count', \n",
    "        data = df_topic_weightage_by_doc, \n",
    "        width = .5, color = 'steelblue')\n",
    "ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))\n",
    "ax2.xaxis.set_major_formatter(tick_formatter)\n",
    "ax2.set_title('Number of Documents by Topic Weightage', fontdict = dict(size = 10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a keyword network based on term frequency and TF-IDF\n",
    "(use the \"to_gephi.csv\" and \"to_gephi2.csv\" files in Gephi for visualisation)\n",
    "source: https://pythondata.com/text-analytics-visualization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that extracts the most common words per poem\n",
    "def get_keywords(token_list, num):\n",
    "    return Counter(token_list).most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the filtered poems into strings\n",
    "poemlist3 = [str(poem) for poem in poemlist2]\n",
    "token_list = [word_tokenize(poem) for poem in poemlist3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = df1[\"title\"].values.tolist()\n",
    "\n",
    "df4 = pd.DataFrame({\"title\": poems, \n",
    "                    \"poet\": poets,\n",
    "                    \"filteredPoem\": poemlist3})\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to extract the top 5 words per poem\n",
    "keywords = [get_keywords(tokens, 5) for tokens in token_list]\n",
    "\n",
    "# Extract the list of keywords \n",
    "unzipped = [zip(*kw)for kw in keywords]\n",
    "kw = [list(x)[0] for x in unzipped]\n",
    "\n",
    "# Convert the list of keywords to a string\n",
    "kw2 = [\",\".join(str(y) for y in x) for x in kw]\n",
    "\n",
    "# Add the list of keywords to the dataframe\n",
    "df4[\"keywords_TF\"] = kw2\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add keywords based on TF-IDF\n",
    "impt_words2 = df3.reset_index().groupby(\"PoemTitle\")[\"Word\"].apply(list)\n",
    "df4[\"keywords_TF-IDF\"] = [\",\".join(str(y) for y in x) for x in impt_words2]\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of keywords according to term frequency\n",
    "keywordsTF = []\n",
    "for i, r in df4.iterrows():\n",
    "    keywords = r[\"keywords_TF\"].split(\",\")\n",
    "    for kw in keywords:\n",
    "        keywordsTF.append((kw.strip(\"\"), r[\"keywords_TF\"]))\n",
    "kwTF_df = pd.DataFrame(keywordsTF).rename(columns = {0: \"keyword\", 1: \"keywords\"})\n",
    "kwTF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of keywords according to TF-IDF\n",
    "keywordsTFIDF = []\n",
    "for i, r in df4.iterrows():\n",
    "    keywords = r[\"keywords_TF-IDF\"].split(\",\")\n",
    "    for kw in keywords:\n",
    "        keywordsTFIDF.append((kw.strip(\"\"), r[\"keywords_TF-IDF\"]))\n",
    "kwTFIDF_df = pd.DataFrame(keywordsTFIDF).rename(columns = {0: \"keyword\", 1: \"keywords\"})\n",
    "kwTFIDF_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rows to lists\n",
    "docsTF = kwTF_df[\"keywords\"].tolist()\n",
    "namesTF = kwTF_df[\"keyword\"].tolist()\n",
    "\n",
    "docs_list = [i.split(\",\")for i in docsTF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an ordered dictionary of keyword and frequency of co-occurrence\n",
    "from collections import OrderedDict\n",
    "occurrences = OrderedDict((name, OrderedDict((name, 0) for name in namesTF)) for name in namesTF)\n",
    "\n",
    "for i in docs_list:\n",
    "    for x in range(len(i)):\n",
    "        for item in i[:x] + i[x + 1:]:\n",
    "            occurrences[i[x]][item] += 1\n",
    "\n",
    "# Create a dataframe of co-occurrences\n",
    "co_occur_df = pd.DataFrame.from_dict(occurrences)         \n",
    "co_occur_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occur_df.to_csv(\"to_gephi.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rows to lists\n",
    "docsTFIDF = kwTFIDF_df[\"keywords\"].tolist()\n",
    "namesTFIDF = kwTFIDF_df[\"keyword\"].tolist()\n",
    "\n",
    "docs_list = [i.split(\",\")for i in docsTFIDF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ordered dictionary of keyword and frequency of co-occurrence\n",
    "from collections import OrderedDict\n",
    "occurrences2 = OrderedDict((name, OrderedDict((name, 0) for name in namesTFIDF)) for name in namesTFIDF)\n",
    "\n",
    "for i in docs_list:\n",
    "    for x in range(len(i)):\n",
    "        for item in i[:x] + i[x + 1:]:\n",
    "            occurrences2[i[x]][item] += 1\n",
    "\n",
    "# Create a dataframe of co-occurrences\n",
    "co_occur_df2 = pd.DataFrame.from_dict(occurrences2)         \n",
    "co_occur_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occur_df2.to_csv(\"to_gephi2.csv\", sep = \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
